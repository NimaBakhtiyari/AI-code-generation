apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: neurosymbolic-training-
  labels:
    app: neurosymbolic-codegen
    workflow-type: training
spec:
  entrypoint: training-pipeline
  
  arguments:
    parameters:
    - name: model-name
      value: "deepseek-coder-6.7b"
    - name: batch-size
      value: "16"
    - name: num-epochs
      value: "3"
    - name: learning-rate
      value: "2e-5"
    - name: num-gpus
      value: "4"
  
  volumeClaimTemplates:
  - metadata:
      name: workspace
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 100Gi
  
  templates:
  - name: training-pipeline
    steps:
    - - name: prepare-environment
        template: setup-env
    - - name: download-model
        template: download-pretrained-model
        arguments:
          parameters:
          - name: model-name
            value: "{{workflow.parameters.model-name}}"
    - - name: prepare-data
        template: prepare-training-data
    - - name: distributed-training
        template: train-distributed
        arguments:
          parameters:
          - name: batch-size
            value: "{{workflow.parameters.batch-size}}"
          - name: num-epochs
            value: "{{workflow.parameters.num-epochs}}"
          - name: learning-rate
            value: "{{workflow.parameters.learning-rate}}"
          - name: num-gpus
            value: "{{workflow.parameters.num-gpus}}"
    - - name: validate-model
        template: model-validation
    - - name: save-artifacts
        template: save-model-artifacts
  
  - name: setup-env
    container:
      image: python:3.11-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          apt-get update && apt-get install -y curl git
          curl -sSL https://install.python-poetry.org | python3 -
          export PATH="/root/.local/bin:$PATH"
          poetry --version
      volumeMounts:
      - name: workspace
        mountPath: /workspace
  
  - name: download-pretrained-model
    inputs:
      parameters:
      - name: model-name
    container:
      image: python:3.11-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          pip install huggingface-hub
          huggingface-cli download {{inputs.parameters.model-name}} \
            --local-dir /workspace/models/pretrained/{{inputs.parameters.model-name}}
      volumeMounts:
      - name: workspace
        mountPath: /workspace
  
  - name: prepare-training-data
    container:
      image: python:3.11-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          cd /workspace
          poetry install
          poetry run python scripts/prepare_data.py
      volumeMounts:
      - name: workspace
        mountPath: /workspace
  
  - name: train-distributed
    inputs:
      parameters:
      - name: batch-size
      - name: num-epochs
      - name: learning-rate
      - name: num-gpus
    container:
      image: nvcr.io/nvidia/pytorch:23.10-py3
      command: ["/bin/bash", "-c"]
      args:
        - |
          cd /workspace
          poetry install
          poetry run deepspeed --num_gpus={{inputs.parameters.num-gpus}} \
            src/neurosymbolic_codegen/train.py \
            --config configs/training_config.yaml \
            --batch-size {{inputs.parameters.batch-size}} \
            --num-epochs {{inputs.parameters.num-epochs}} \
            --learning-rate {{inputs.parameters.learning-rate}} \
            --deepspeed configs/deepspeed_config.json
      resources:
        limits:
          nvidia.com/gpu: "{{inputs.parameters.num-gpus}}"
      volumeMounts:
      - name: workspace
        mountPath: /workspace
  
  - name: model-validation
    container:
      image: python:3.11-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          cd /workspace
          poetry run python -m neurosymbolic_codegen.evaluate \
            --config configs/eval_config.yaml \
            --checkpoint /workspace/models/checkpoints/latest
      volumeMounts:
      - name: workspace
        mountPath: /workspace
  
  - name: save-model-artifacts
    container:
      image: python:3.11-slim
      command: ["/bin/bash", "-c"]
      args:
        - |
          cd /workspace
          tar -czf model-artifacts.tar.gz models/finetuned/ models/checkpoints/
          echo "Artifacts saved to /workspace/model-artifacts.tar.gz"
      volumeMounts:
      - name: workspace
        mountPath: /workspace
    outputs:
      artifacts:
      - name: model-artifacts
        path: /workspace/model-artifacts.tar.gz
